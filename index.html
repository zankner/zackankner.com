<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Fontawesome Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css"
        integrity="sha512-MV7K8+y+gLIBoVD59lQIYicR65iaqukzvf/nwasF0nqhPay5w/9lJmVM2hMDcnK1OnMGCdVK+iQrJ7lzPJQd1w=="
        crossorigin="anonymous" referrerpolicy="no-referrer" />
    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css"
        integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

    <title>Zack Ankner</title>
</head>

<body>
    <div class="container mt-5">
        <div class="d-flex justify-content-center">
            <div class="col-md-6">
                <h2>Zack Ankner</h2>
                <p class="mt-4 mb-0">
                    I am a third year undergraduate student at MIT currently studying Computer Science and Mathematics.
                    I currently work in the Programming Systems Group (PSG) led by <a
                        href="https://people.csail.mit.edu/mcarbin/">Michael Carbin</a>, and I am supervised by
                    <a href="https://alexrenda.com/">Alex Renda</a>.
                    At PSG I have led both a project on Transformers that are invariant to variable renamings and an
                    empirical investigation of the effect data dimensionality has on neural network prunability.
                    I also work as a research scientist intern at <a href="https://www.mosaicml.com/">MosaicML</a>,
                    where I am investigating efficient methods for LLM pretraining and inference.
                </p>
                <p class="mt-3">
                    In general I am interested in a variety of topics and happy to chat about anything ML related at all
                    so reach out.
                    I am currently focussing on the effect of pretraining data on models and also on systems speedups
                    for ML.
                </p>
                <p class="mt-3">
                    You can find my resume <a href="resume.pdf">here</a>.
                </p>
            </div>
            <div class="col-md-3 centered text-center">
                <img class="img-fluid rounded w-75 mx-auto" src="profile.jpeg" />
                <div class="text-center mt-4">
                    <p class="mb-0"><a href="mailto:ankner@mit.edu" class="" target="_blank"><i
                                class="fa-solid fa-envelope"></i>
                            ankner@mit.edu</a></p>
                    <p class="mb-0"><a href="https://twitter.com/ZackAnkner" class="" target="_blank"><i
                                class="fa-brands fa-twitter"></i>
                            @ZackAnkner</a></p>
                    <p class="mb-0"><a href="https://scholar.google.com/citations?user=AaKpmFYAAAAJ&hl=en&oi=ao"
                            class="" target="_blank"><i class="fa fa-graduation-cap"></i>
                            Zachary Ankner</a></p>
                </div>
            </div>
        </div>

        <div class="mt-5 d-flex justify-content-center">
            <div class="col-md-9">
                <h2 class="mb-1">Papers <small style="font-size: small;">(* denotes equal contribution)</small></h2>

                <div class="mt-4">
                    <a href="https://arxiv.org/abs/2311.09431">Striped Attention: Faster Ring Attention for Causal
                        Transformers
                    </a>
                    <p class="mb-0">William Brandon*, Aniruddha Nrusimha, Kevin Qian, <u>Zachary Ankner</u>, Tian Jin,
                        Zhiye Song, and Jonathan Ragan-Kelly
                        Leavitt</p>
                    <p class="mb-0">Preprint</p>
                </div>

                <div class="mt-4">
                    <a href="https://arxiv.org/abs/2305.15096">Dynamic Masking Rate Schedules for MLM Pretraining
                    </a>
                    <p class="mb-0"><u>Zachary Ankner</u>*, Naomi Saphra, Davis Blalock, Jonathan Frankle, Matthew L
                        Leavitt</p>
                    <p class="mb-0">Preprint</p>
                </div>

                <div class="mt-4">
                    <a href="https://arxiv.org/abs/2211.16677">3D Neural Field Generation using Triplane Diffusion
                    </a>
                    <p class="mb-0">J.Ryan Shue*, Eric Ryan Chan*, Ryan Po*, <u>Zachary Ankner</u>*, Jiajun Wu, and
                        Gordon Wetzstein</p>
                    <p class="mb-0">CVPR 2023, Poster</p>
                    <p><a href="https://jryanshue.com/nfd/index.html">Project page</a>, <a
                            href="https://github.com/JRyanShue/NFD">Code</a></p>
                </div>

                <div class="mt-4">
                    <a href="https://arxiv.org/abs/2212.00291">The Effect of Data Dimensionality on Neural Network
                        Prunability
                    </a>
                    <p class="mb-0"><u>Zachary Ankner</u>*, Alex Renda, Gintare Karolina Dziugaite, Jonathan Frankle,
                        and Tian Jin</p>
                    <p class="mb-0">NeurIPS 2022, ICBINB Workshop</p>
                </div>

                <div class="mt-4">
                    <a href="https://www.worldscientific.com/doi/10.1142/S0218001422590170">EntailSum: An
                        Entailment-Based Approach to Aspect-Based Text Summarization with Automated Aspect
                        Adaptation
                    </a>
                    <p class="mb-0"><u>Zachary Ankner</u>*, Purvaja Balaji, Ye Zhu, Chun Keat Hiew, Patrick Wang, and
                        Amar Gupta</p>
                    <p class="mb-5">International Journal of Pattern Recognition and Artificial Intelligence</p>
                </div>
            </div>
        </div>
    </div>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js"
        integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.3/dist/umd/popper.min.js"
        integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/js/bootstrap.min.js"
        integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
        crossorigin="anonymous"></script>
</body>

</html>